{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a1f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 40_ngame-for-amazon131-with-input-concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b776411",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8936c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os,torch, torch.multiprocessing as mp, pickle, numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from xcai.basics import *\n",
    "from xcai.models.PPP0XX import DBT009,DBT011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441a688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8906ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['WANDB_PROJECT']='medic_09-amazon131'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042dfd3b-be4b-4426-a6f8-a44ac33f873b",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f2acbc-48d5-4117-9170-47f2cbdf94e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def separate_title_and_content(input_text):\n",
    "    title,content = [],[]\n",
    "    for o in tqdm(input_text):\n",
    "        text = o.split('  ', maxsplit=1)\n",
    "\n",
    "        if len(text) == 2: \n",
    "            t,c = text\n",
    "        else: \n",
    "            t,c = text[0], ''\n",
    "\n",
    "        title.append(t)\n",
    "        content.append(c)\n",
    "    return title, content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c4bc9f-d9c0-4fa8-b874-227300f9e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tokenize(tokenizer, info):\n",
    "    o = tokenizer(info['input_text'], truncation=True, max_length=32)\n",
    "    info.update(o)\n",
    "    \n",
    "    o = tokenizer(info['content_text'], truncation=True, max_length=1024)\n",
    "    \n",
    "    info['content_input_ids'] = o['input_ids']\n",
    "    info['content_attention_mask'] = o['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4234bb-de92-4164-b850-0bf8e0f8a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def append_sep_token(input_ids, attention_mask):\n",
    "    sep_tok = input_ids[0][-1]\n",
    "    \n",
    "    new_input_ids = [o+[sep_tok] for o in input_ids]\n",
    "    new_attention_mask = [o+[1] for o in attention_mask]\n",
    "    \n",
    "    return new_input_ids, new_attention_mask\n",
    "\n",
    "\n",
    "def append_sep_token_into_block(block):\n",
    "    dset_type = ['train', 'test']\n",
    "    info_type = ['data_info', 'lbl_info']\n",
    "    \n",
    "    for dt in dset_type:\n",
    "        dset = getattr(block, dt)\n",
    "        for it in info_type:\n",
    "            info = getattr(dset.dset.data, it)\n",
    "            input_ids, attention_mask = append_sep_token(info['input_ids'], info['attention_mask'])\n",
    "            info['input_ids'],info['attention_mask'] = input_ids, attention_mask\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d8642f-c282-48a4-8629-ee570b9e358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def concatenate_title_and_content_ids(info, max_input_length, exclude_sep_tok=True):\n",
    "    n_data = len(info['input_ids'])\n",
    "    sep_tok = info['input_ids'][0][-1]\n",
    "    \n",
    "    for i,(p,q) in tqdm(enumerate(zip(info['input_ids'],info['content_input_ids'])), total=n_data):\n",
    "        input_ids = p[:-1] + q[1:] if exclude_sep_tok else p + q[1:]\n",
    "        if len(input_ids) > max_input_length:\n",
    "            input_ids = input_ids[:max_input_length-1] + [sep_tok]\n",
    "        info['input_ids'][i] = input_ids\n",
    "    \n",
    "    for i,(p,q) in tqdm(enumerate(zip(info['attention_mask'],info['content_attention_mask'])), total=n_data):\n",
    "        attention_mask = p[:-1] + q[1:] if exclude_sep_tok else p + q[1:]\n",
    "        if len(attention_mask) > max_input_length:\n",
    "            attention_mask = attention_mask[:max_input_length-1] + [1]\n",
    "        info['attention_mask'][i] = attention_mask\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3609898-94ec-41ab-9a70-cc0bcf8cbb5d",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5f9db-a09d-4d30-b790-c799f48c704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    build_block = False\n",
    "    data_dir = '/home/scai/phd/aiz218323/Projects/XC_NLG/data'\n",
    "    pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "\n",
    "    \"\"\" Load data \"\"\"    \n",
    "    pkl_file = f'{pkl_dir}/processed/amazon131_data-meta_distilbert-base-uncased_xcs_cat-512.pkl'\n",
    "    if build_block:\n",
    "        block = XCBlock.from_cfg(data_dir, 'data_meta', dset='amazontitles131', transform_type='xcs', tokenizer='distilbert-base-uncased', \n",
    "                                 sampling_features=[('lbl2data',1)], oversample=False)\n",
    "\n",
    "        train_title, train_content = separate_title_and_body(block.train.dset.data.data_info['input_text'])\n",
    "        test_title, test_content = separate_title_and_body(block.test.dset.data.data_info['input_text'])\n",
    "\n",
    "        block.train.dset.data.data_info['input_text'] = train_title\n",
    "        block.train.dset.data.data_info['content_text'] = train_content\n",
    "        \n",
    "        block.test.dset.data.data_info['input_text'] = test_title\n",
    "        block.test.dset.data.data_info['content_text'] = test_content\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        tokenize(tokenizer, block.train.dset.data.data_info)\n",
    "        tokenize(tokenizer, block.test.dset.data.data_info)\n",
    "\n",
    "        append_sep_token_into_block(block)\n",
    "\n",
    "        block = AugmentMetaInputIdsTfm.apply(block, 'cat_meta', 'data', 256, True)\n",
    "        block = AugmentMetaInputIdsTfm.apply(block, 'cat_meta', 'lbl', 256, True)\n",
    "\n",
    "        block.train.dset.data.data_info['input_ids'] = block.train.dset.data.data_info['input_ids_aug_cat']\n",
    "        block.train.dset.data.data_info['attention_mask'] = block.train.dset.data.data_info['attention_mask_aug_cat']\n",
    "        block.test.dset.data.data_info['input_ids'] = block.test.dset.data.data_info['input_ids_aug_cat']\n",
    "        block.test.dset.data.data_info['attention_mask'] = block.test.dset.data.data_info['attention_mask_aug_cat']\n",
    "        \n",
    "        block.train.dset.data.lbl_info['input_ids'] = block.train.dset.data.lbl_info['input_ids_aug_cat']\n",
    "        block.train.dset.data.lbl_info['attention_mask'] = block.train.dset.data.lbl_info['attention_mask_aug_cat']\n",
    "        block.test.dset.data.lbl_info['input_ids'] = block.test.dset.data.lbl_info['input_ids_aug_cat']\n",
    "        block.test.dset.data.lbl_info['attention_mask'] = block.test.dset.data.lbl_info['attention_mask_aug_cat']\n",
    "\n",
    "        concatenate_title_and_content_ids(block.train.dset.data.data_info, 512, exclude_sep_tok=False)\n",
    "        concatenate_title_and_content_ids(block.test.dset.data.data_info, 512, exclude_sep_tok=False)\n",
    "        \n",
    "        with open(pkl_file, 'wb') as file: pickle.dump(block, file)\n",
    "    else:\n",
    "        with open(pkl_file, 'rb') as file: block = pickle.load(file)\n",
    "\n",
    "    block.train.dset.meta = {}\n",
    "    block.test.dset.meta = {}\n",
    "    \n",
    "    \"\"\" Training Arguements \"\"\"\n",
    "    args = XCLearningArguments(\n",
    "        output_dir='/home/scai/phd/aiz218323/scratch/outputs/medic/40_ngame-for-amazon131-with-input-concatenation',\n",
    "        logging_first_step=True,\n",
    "        per_device_train_batch_size=800,\n",
    "        per_device_eval_batch_size=800,\n",
    "        representation_num_beams=200,\n",
    "        representation_accumulation_steps=10,\n",
    "        save_strategy=\"steps\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=5000,\n",
    "        save_steps=5000,\n",
    "        save_total_limit=5,\n",
    "        num_train_epochs=300,\n",
    "        predict_with_representation=True,\n",
    "        representation_search_type='BRUTEFORCE',\n",
    "        adam_epsilon=1e-6,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=2e-4,\n",
    "        \n",
    "        group_by_cluster=True,\n",
    "        num_clustering_warmup_epochs=10,\n",
    "        num_cluster_update_epochs=5,\n",
    "        num_cluster_size_update_epochs=25,\n",
    "        clustering_type='EXPO',\n",
    "        minimum_cluster_size=2,\n",
    "        maximum_cluster_size=1600,\n",
    "        \n",
    "        metric_for_best_model='P@1',\n",
    "        load_best_model_at_end=True,\n",
    "        target_indices_key='plbl2data_idx',\n",
    "        target_pointer_key='plbl2data_data2ptr',\n",
    "        \n",
    "        use_encoder_parallel=True,\n",
    "        max_grad_norm=None,\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                      pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "    model = DBT009.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', bsz=bsz, tn_targ=5000, margin=0.3, tau=0.1, \n",
    "                                   n_negatives=10, apply_softmax=True, use_encoder_parallel=True)\n",
    "    model.init_dr_head()\n",
    "\n",
    "    \n",
    "    learn = XCLearner(\n",
    "        model=model, \n",
    "        args=args,\n",
    "        train_dataset=block.train.dset,\n",
    "        eval_dataset=block.test.dset,\n",
    "        data_collator=block.collator,\n",
    "        compute_metrics=metric,\n",
    "    )\n",
    "    \n",
    "    mp.freeze_support()\n",
    "    learn.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a095df-0b9e-4f5e-80b1-a5b2372331fd",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3372c7-7bfe-436f-8d52-3b8a10f65e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = XCLearningArguments(\n",
    "    output_dir='/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-2',\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=800,\n",
    "    per_device_eval_batch_size=800,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=100,\n",
    "    predict_with_representation=True,\n",
    "    representation_search_type='BRUTEFORCE',\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    use_encoder_parallel=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1438e-cdf1-4f2e-9991-f20e9aef027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875acda-5cee-45c1-b88e-e90273819396",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"/home/scai/phd/aiz218323/scratch/outputs/{os.path.basename(args.output_dir)}\"\n",
    "mname = f'{output_dir}/{os.path.basename(get_best_model(output_dir))}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d74986-4c79-40d2-b984-0a7e4ccb9197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a2193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT009 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "model = DBT009.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', bsz=bsz, tn_targ=5000, margin=0.3, tau=0.1,\n",
    "                               n_negatives=10, apply_softmax=True, use_encoder_parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3e381-5e85-4411-99a0-54413275e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "model_weight_file = f'{mname}/model.safetensors'\n",
    "\n",
    "model_weights = {}\n",
    "with safe_open(model_weight_file, framework=\"pt\") as file:\n",
    "    for k in file.keys(): model_weights[k] = file.get_tensor(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1bd6b-1778-4805-910e-63e921ca950e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_weights, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7813b43-75d1-45d9-a715-a726a6bee2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57a038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fee6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3968dd1cdc67413ea42d559d32ca42f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "o = learn.predict(block.test.dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08e7e0-e5bc-4339-b124-f1af1d20df00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.1771</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>12.2884</td>\n",
       "      <td>7.9308</td>\n",
       "      <td>24.1771</td>\n",
       "      <td>24.4573</td>\n",
       "      <td>25.4609</td>\n",
       "      <td>27.2161</td>\n",
       "      <td>20.1098</td>\n",
       "      <td>21.5063</td>\n",
       "      <td>23.1904</td>\n",
       "      <td>26.8649</td>\n",
       "      <td>20.1098</td>\n",
       "      <td>22.0686</td>\n",
       "      <td>23.477</td>\n",
       "      <td>25.37</td>\n",
       "      <td>31.8421</td>\n",
       "      <td>46.4144</td>\n",
       "      <td>49.9468</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>262.9244</td>\n",
       "      <td>675.156</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3      P@5    P@10      N@1      N@3      N@5     N@10  \\\n",
       "0  24.1771  16.1361  12.2884  7.9308  24.1771  24.4573  25.4609  27.2161   \n",
       "\n",
       "     PSP@1    PSP@3    PSP@5   PSP@10    PSN@1    PSN@3   PSN@5  PSN@10  \\\n",
       "0  20.1098  21.5063  23.1904  26.8649  20.1098  22.0686  23.477   25.37   \n",
       "\n",
       "      R@10    R@100    R@200    loss   runtime  samples_per_second  \\\n",
       "0  31.8421  46.4144  49.9468  0.0294  262.9244             675.156   \n",
       "\n",
       "   steps_per_second  \n",
       "0             0.422  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436ccd3-e21c-454c-a24f-508f4afc2299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-2/checkpoint-85000'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bcf9a-c9c0-4da2-8f49-97163fd5c552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6484280-d56f-43af-85a7-57c1a7e1c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = f\"{mname}/predictions/\"\n",
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "with open(f'{pred_dir}/test_predictions.pkl', 'wb') as file: pickle.dump(o, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a35c47-8224-4117-8dc8-19de6dc840a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
