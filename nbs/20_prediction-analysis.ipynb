{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8bb599-0015-42c8-8081-8c2e5d561979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 20_prediction-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ed1484-8552-4f0f-be84-396a051c77a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8713334a-d3a7-425f-80c0-27eef599e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from xcai.basics import *\n",
    "from xcai.analysis import *\n",
    "\n",
    "from xclib.utils.sparse import retain_topk\n",
    "\n",
    "from IPython.display import HTML,display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a8a6f-ca15-488e-ba8e-fdc0d3f11627",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244b6164-3583-4d85-bb7f-7ae9c6fe3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def display_momos(momos_dset:Dataset, oak_dset:Dataset, test_dset:Dataset, idxs:List):\n",
    "    df = pd.DataFrame([test_dset[i] for i in idxs])\n",
    "\n",
    "    df = df.rename({'data_input_text':'Document', 'lbl2data_input_text': 'Ground truth labels', 'lnk2data_input_text':'Predicted metadata'}, axis=1)\n",
    "    momos_df = pd.DataFrame({'MOMOS predictions': [momos_dset[i]['lbl2data_input_text'] for i in idxs]})\n",
    "    oak_df = pd.DataFrame({'OAK predictions': [oak_dset[i]['lbl2data_input_text'] for i in idxs]})\n",
    "    \n",
    "    df = pd.concat([df, momos_df, oak_df], axis=1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557748f-16a8-4291-a62e-dad90c5bcb22",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1507e-aa44-483f-af10-d1ab88bcd7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    topk,num_preds,metric,num_data = 5,10,'P',10\n",
    "    dataset_name = 'wikiseealsotitles'\n",
    "    pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets/'\n",
    "    odir_a = '/home/scai/phd/aiz218323/scratch/outputs/64-ngame-ep-for-wikiseealso-with-entropy-loss-1-0'\n",
    "    odir_b = '/home/scai/phd/aiz218323/scratch/outputs/64-ngame-ep-for-wikiseealso-with-entropy-loss-1-0'\n",
    "\n",
    "    \"\"\" Load data \"\"\"\n",
    "    pkl_file = f'{pkl_dir}/processed/{dataset_name}_data-metas_distilbert-base-uncased_xcs.pkl'\n",
    "    with open(pkl_file, 'rb') as file: block = pickle.load(file)\n",
    "\n",
    "    \"\"\" Load predictions \"\"\"\n",
    "    pred_file = f'{odir_a}/predictions/test_predictions.pkl'\n",
    "    plbl_a = get_pred_sparse(pred_file, block.n_lbl)\n",
    "    \n",
    "    pred_file = f'{odir_b}/predictions/test_predictions.pkl'\n",
    "    plbl_b = get_pred_sparse(pred_file, block.n_lbl)\n",
    "\n",
    "    \"\"\" Analysis \"\"\"\n",
    "    pattern = r'^(data|lbl2data|lbl2data_aug_cat)_input_text$'\n",
    "\n",
    "    pdset_a = TextColumns(get_pred_dset(retain_topk(plbl_a, k=num_preds), block), pat=pattern)\n",
    "    pdset_b = TextColumns(get_pred_dset(retain_topk(plbl_b, k=num_preds), block), pat=pattern)\n",
    "    test_dset = TextColumns(block.test.dset, pat=pattern)\n",
    "\n",
    "    eval_a = pointwise_eval(plbl_a, block.test.dset.data.data_lbl, block.test.dset.data.data_filterer, topk=topk, metric=metric)\n",
    "    eval_b = pointwise_eval(plbl_b, block.test.dset.data.data_lbl, block.test.dset.data.data_filterer, topk=topk, metric=metric)\n",
    "    eval_a = np.array(eval_a.sum(axis=1)).squeeze()\n",
    "    eval_b = np.array(eval_b.sum(axis=1)).squeeze()\n",
    "    idxs = np.argsort(eval_b - eval_a)[:num_data]\n",
    "\n",
    "    display(HTML(compare_text(pdset_a, pdset_b, test_dset, idxs)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fbf515-8c1a-40ef-8386-8d6f0c22b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    topk,num_preds,metric = 5,10,'P'\n",
    "    dataset_name = 'wikiseealsotitles'\n",
    "    pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets/'\n",
    "    odir_a = '/home/scai/phd/aiz218323/scratch/outputs/64-ngame-ep-for-wikiseealso-with-entropy-loss-1-0'\n",
    "    odir_b = '/home/scai/phd/aiz218323/scratch/outputs/64-ngame-ep-for-wikiseealso-with-entropy-loss-1-0'\n",
    "\n",
    "    output_file = 'output.csv'\n",
    "\n",
    "    \"\"\" Load data \"\"\"\n",
    "    pkl_file = f'{pkl_dir}/processed/{dataset_name}_data-lnk_distilbert-base-uncased_xcs.pkl'\n",
    "    with open(pkl_file, 'rb') as file: block = pickle.load(file)\n",
    "\n",
    "    data_meta = retain_topk(block.test.dset.meta.lnk_meta.data_meta, k=3)\n",
    "    lbl_meta = block.test.dset.meta.lnk_meta.lbl_meta\n",
    "    block.test.dset.meta.lnk_meta.update_meta_matrix(data_meta, lbl_meta)\n",
    "\n",
    "    \"\"\" Load predictions \"\"\"\n",
    "    pred_file = f'{odir_a}/predictions/test_predictions.pkl'\n",
    "    plbl_a = get_pred_sparse(pred_file, block.n_lbl)\n",
    "    \n",
    "    pred_file = f'{odir_b}/predictions/test_predictions.pkl'\n",
    "    plbl_b = get_pred_sparse(pred_file, block.n_lbl)\n",
    "\n",
    "    \"\"\" Analysis \"\"\"\n",
    "    pattern = r'^(data|lbl2data|lnk2data)_input_text$'\n",
    "\n",
    "    pdset_a = TextColumns(get_pred_dset(retain_topk(plbl_a, k=topk), block), pat=pattern)\n",
    "    pdset_b = TextColumns(get_pred_dset(retain_topk(plbl_b, k=topk), block), pat=pattern)\n",
    "    test_dset = TextColumns(block.test.dset, pat=pattern)\n",
    "\n",
    "    eval_a = pointwise_eval(plbl_a, block.test.dset.data.data_lbl, block.test.dset.data.data_filterer, topk=topk, metric=metric)\n",
    "    eval_b = pointwise_eval(plbl_b, block.test.dset.data.data_lbl, block.test.dset.data.data_filterer, topk=topk, metric=metric)\n",
    "    \n",
    "    eval_a = np.array(eval_a.sum(axis=1)).squeeze()\n",
    "    eval_b = np.array(eval_b.sum(axis=1)).squeeze()\n",
    "    idxs = np.argsort(eval_b - eval_a)\n",
    "\n",
    "    df = display_momos(pdset_a, pdset_b, test_dset, idxs)\n",
    "    df.to_csv(output_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa5452-911c-4396-b63f-c069817d1b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9338b00-452f-4429-98ff-6e67544c51b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
