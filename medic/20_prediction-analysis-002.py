# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/20_prediction-analysis.ipynb.

# %% auto 0
__all__ = ['display_momos']

# %% ../nbs/20_prediction-analysis.ipynb 2
import pandas as pd, os, pickle, numpy as np, scipy.sparse as sp
from typing import List
from tqdm.auto import tqdm
from torch.utils.data import Dataset

from xcai.basics import *
from xcai.analysis import *

from xclib.utils.sparse import retain_topk

from IPython.display import HTML,display

# %% ../nbs/20_prediction-analysis.ipynb 4
def display_momos(momos_dset:Dataset, oak_dset:Dataset, ngame_dset:Dataset, oracle_dset:Dataset, test_dset:Dataset, idxs:List):
    df = pd.DataFrame([test_dset[i] for i in tqdm(idxs)])

    df = df.rename({'data_input_text':'Document', 'lbl2data_input_text': 'Ground truth labels', 'lnk2data_input_text':'Predicted metadata', 
        'cat2data_input_text': 'Oracle metadata'}, axis=1)

    momos_df = pd.DataFrame({'MOMOS predictions': [momos_dset[i]['lbl2data_input_text'] for i in tqdm(idxs)]})
    oak_df = pd.DataFrame({'OAK predictions': [oak_dset[i]['lbl2data_input_text'] for i in tqdm(idxs)]})

    ngame_df = pd.DataFrame({'NGAME predictions': [ngame_dset[i]['lbl2data_input_text'] for i in tqdm(idxs)]})
    oracle_df = pd.DataFrame({'Oracle predictions': [oracle_dset[i]['lbl2data_input_text'] for i in tqdm(idxs)]})
    
    df = pd.concat([df, momos_df, oak_df, ngame_df, oracle_df], axis=1)
    return df
    
# %% ../nbs/20_prediction-analysis.ipynb 7
if __name__ == '__main__':
    topk,num_preds,metric = 5,10,'P'

    dataset_name = 'wikiseealsotitles'
    pkl_dir = '/home/aiscuser/scratch1/datasets/'
    odir_a = '/data/Projects/xc_nlg/outputs/86-distillation-for-wikiseealso-with-oak-7-3-4'
    odir_b = '/data/Projects/xc_nlg/outputs/85-oak-dr-ep-for-wikiseealso-with-additive-renee-embedding-5-3'
    
    odir_c = '/data/to_b/ngame_wikiseealsotitles.npz'
    odir_d = '/data/Projects/xc_nlg/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-6-3/predictions/test_predictions.npz'

    #os.makedirs(f'{odir_a}/examples/', exist_ok=True)
    #mname = os.path.basename(odir_b)
    output_file = 'examples.csv'

    """ Load data """
    pkl_file = f'{pkl_dir}/processed/{dataset_name}_data-cat-lnk_distilbert-base-uncased_xcs.pkl'
    with open(pkl_file, 'rb') as file: block = pickle.load(file)

    data_meta = retain_topk(block.test.dset.meta.lnk_meta.data_meta, k=3)
    lbl_meta = block.test.dset.meta.lnk_meta.lbl_meta
    block.test.dset.meta.lnk_meta.update_meta_matrix(data_meta, lbl_meta)

    """ Load predictions """
    pred_file = f'{odir_a}/predictions/test_predictions.pkl'
    plbl_a = get_pred_sparse(pred_file, block.n_lbl)
    plbl_a = Filterer.apply(plbl_a, block.test.dset.data.data_lbl_filterer)
    
    pred_file = f'{odir_b}/predictions/test_predictions.pkl'
    plbl_b = get_pred_sparse(pred_file, block.n_lbl)
    plbl_b = Filterer.apply(plbl_b, block.test.dset.data.data_lbl_filterer)

    plbl_c = sp.load_npz(odir_c)
    plbl_c = Filterer.apply(plbl_c, block.test.dset.data.data_lbl_filterer)

    plbl_d = sp.load_npz(odir_d)
    plbl_d = Filterer.apply(plbl_d, block.test.dset.data.data_lbl_filterer)

    """ Analysis """
    pattern = r'^(data|lbl2data|lnk2data|cat2data)_input_text$'

    pdset_a = TextColumns(get_pred_dset(retain_topk(plbl_a, k=topk), block), pat=pattern)
    pdset_b = TextColumns(get_pred_dset(retain_topk(plbl_b, k=topk), block), pat=pattern)

    pdset_c = TextColumns(get_pred_dset(retain_topk(plbl_c, k=topk), block), pat=pattern)
    pdset_d = TextColumns(get_pred_dset(retain_topk(plbl_d, k=topk), block), pat=pattern)

    test_dset = TextColumns(block.test.dset, pat=pattern)


    eval_a = pointwise_eval(plbl_a, block.test.dset.data.data_lbl, block.test.dset.data.data_lbl_filterer, topk=topk, metric=metric)
    eval_b = pointwise_eval(plbl_b, block.test.dset.data.data_lbl, block.test.dset.data.data_lbl_filterer, topk=topk, metric=metric)
    eval_a = np.array(eval_a.sum(axis=1)).squeeze()
    eval_b = np.array(eval_b.sum(axis=1)).squeeze()

    idxs = np.argsort(eval_b - eval_a)
    # idxs = np.argsort(eval_a - eval_b)

    #scores = np.array(data_meta.mean(axis=1)).squeeze()
    #idxs_k = idxs[:1000]
    #scores_k = scores[idxs_k]
    #idxs = idxs_k[np.argsort(-scores_k)]

    df = display_momos(pdset_a, pdset_b, pdset_c, pdset_d, test_dset, idxs)
    df['MOMOS scores'] = eval_a[idxs]
    df['OAK scores'] = eval_b[idxs]

    cols = ['Document', 'Oracle metadata', 'Predicted metadata', 'Ground truth labels','MOMOS predictions','OAK predictions','NGAME predictions','Oracle predictions','MOMOS scores','OAK scores']

    df[cols].to_csv(output_file)

    
